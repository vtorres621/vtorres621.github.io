<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Victor Torres</title>
    
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link href="css/bootstrap.min.css" rel="stylesheet" media="screen">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>

    <meta name="author" content="Victor Torres">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="Description" content="Victor Torres | RA at ASU Imaging Lyceum | "">
    <meta name="keywords" content="Victor Torres, ASU, Computer Vision, Machine Learning">

    <link rel="icon" type="image/png" href="">

    <!-- Replace Google Analytics tag with your own if you are cloning this template -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <!--
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-8EQTMHM42K"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-8EQTMHM42K');
    </script> -->

</head>
<body class="bg_colour">
    <table border=0 class="bg_colour" style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr style="padding:0px">
            <td style="padding:0px">
                
                <!-- Name tab -->
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    <tr style="padding:0px">
                      <td style="padding:2.5%;width:63%;vertical-align:middle">
                        <p style="text-align:center">
                          <name>Victor Torres</name>
                        </p>
                        <p>I am a Master's in Computer Engineering student at ASU.  Currently working at the <a href="https://web.asu.edu/imaging-lyceum/home">Imaging Lyceum</a>, 
                            where I perform research on computer vision, machine learning and Field Programmable Gate Arrays (FPGAs).
                        </p>
                        <!-- <p>
                          At Google I've worked on <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://www.google.com/get/cardboard/jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, and <a href="https://www.youtube.com/watch?v=JSnB06um5r4">Glass</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I did my bachelors at the <a href="http://cs.toronto.edu">University of Toronto</a>.
                          I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.
                        </p> -->
                        <p style="text-align:center">
                          <a href="mailto:v.torres621@gmail.com">Email</a> &nbsp/&nbsp
                          <a href="data/VictorTorres-CV.pdf">CV</a> &nbsp/&nbsp
                          <!--<a href="data/Victor Torres-bio.txt">Bio</a> &nbsp/&nbsp -->
                          <!--  <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp/&nbsp
                          <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                          <a href="https://github.com/vtorres621">Github</a>
                        </p>
                      </td>
                      <td style="padding:2.5%;width:40%;max-width:40%">
                        <a href="images/VictorTorres.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/VictorTorres-circle.png" class="hoverZoomLink"></a>
                      </td>
                    </tr>
                  </tbody></table>
  
<!-- Education -->

                <button style="border:0px transparent; background-color: transparent;outline:none;"type="button" class="collapsible" data-toggle="collapse" data-target="#content-education" id="education"><heading>Education</heading></button>
                <div id="content-experience" class="collapse in">

                <table border=0 class="bg_colour" style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>
                    <!-- ASU -->
                    <tr>
                        <td style="padding:10px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/ASU-logo.png' width="150" class="side-image">
                            </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                            <!-- <papertitle style="color:gray"><big>Software Development Engineer Intern</big> </papertitle> <papertitle ><big> | Expedia Group</big></papertitle> -->
                            <papertitle><big>Arizona State University</big></papertitle>
                            <br>
                            <papertitle style="color:gray"><big>Master's in </big></papertitle><papertitle><big>Computer Engineering</big></papertitle>
                            <br>
                            August '20 - May '22
                            <br>
                            <br>
                            <p>
                                <!-- Student Societies:
                                <ul>
                                    <li>General Secretary | Academic and Career Council, Students' Gymkhana</li>
                                    <li>Coordinator | NJACK - Computer Science society</li>
                                    <li>Coordinator | Student Mentorship Program and Freshman Forum</li> 
                                    <li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Member | Anwesha - Annual cultural festival</li>
                                </ul> -->
                            </p>
                        </td>
                    </tr>
                    <!-- ITESM -->
                    <tr>
                        <td style="padding:10px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/ITESM.png' width="150" class="side-image">
                            </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                            <!-- <papertitle style="color:gray"><big>Software Development Engineer Intern</big> </papertitle> <papertitle ><big> | Expedia Group</big></papertitle> -->
                            <papertitle><big>Instituto Tecnol√≥gico y de Estudios Superiores de Monterrey</big></papertitle>
                            <br>
                            <papertitle style="color:gray"><big>Bachelor's in </big></papertitle><papertitle><big>Mechatronics Engineering</big></papertitle>
                            <br>
                            August '14 - May '18
                            <br>
                            <br>
                        </td>
                    </tr>
                </tbody></table>
                </div>
                <hr class="soft">

<!-- Experience -->
            
                <button style="border:0px transparent; background-color: transparent;outline:none;"type="button" class="collapsible" data-toggle="collapse" data-target="#content-experience" id="experience"><heading>Experience</heading></button>
                <div id="content-experience" class="collapse in">

                <table border=0 class="bg_colour" style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-top: 10px;"><tbody>
                    <!--ASU RA-->
                    <tr>
                        <td style="padding:10px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/ASU-logo.png' width="150" class="side-image">
                            </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                            <papertitle style="color:gray"><big>Research Assistant</big> </papertitle> <papertitle ><big> | Imaging Lyceum at ASU</big></papertitle>
                            <br>
                            Aug '20 - May '22
                            <br>
                            <br>
                            <p>
                                <ul>
                                    <li>Deploying computer vision and machine learning algorithms on FPGAs.</li>
                                    <li>Improving imaging for outdoor robotic vision applications with neuromorphic (event) cameras.</li>
                                </ul>
                            </p>
                        </td>
                    </tr>

                    <!--Astrobotic-->
                    <!--
                    <tr>
                        <td style="padding:10px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/ASU-logo.png' width="120" class="side-image">
                            </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                            <papertitle style="color:gray"><big>Research Assistant</big> </papertitle> <papertitle ><big> | Imaging Lyceum at ASU</big></papertitle>
                            <br>
                            Aug '20 - May '22
                            <br>
                            <br>
                            <p>
                                <ul>
                                    <li>Deploying computer vision and machine learning algorithms on FPGAs.</li>
                                    <li>Improving imaging for outdoor robotic vision applications with neuromorphic (event) cameras.</li>
                                </ul>
                            </p>
                        </td>
                    </tr>-->
                    
                    <!--Electrical Engineer Torres Electric-->
                    <tr>
                        <td style="padding:10px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/torresElectric.png' width="150" class="side-image">
                            </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                            <papertitle style="color:gray"><big>Electrical Engineer</big> </papertitle> <papertitle ><big> | Torres Electric </big></papertitle>
                            <br>
                            Oct '19 - Aug '20
                            <br>
                            <br>
                            <p>
                                <ul>
                                    <li>Short-circuit, arc flash and protection coordination studies.</li>
                                    <li>Power quality measurement equipment installation.</li>
                                    <li>Thermography Studies on electrical equipment.</li>
                                </ul>
                            </p>
                        </td>
                    </tr>
                    
                    <!--Product Coordinator Bosch-->
                    <tr>
                        <td style="padding:10px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/Bosch-Logo.png' width="180" class="side-image">
                            </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                            <papertitle style="color:gray"><big>Product Coordinator</big> </papertitle> <papertitle ><big> | Robert Bosch GmBH</big></papertitle>
                            <br>
                            Aug '17 - Oct '19
                            <br>
                            <br>
                            <p>
                                <ul>
                                    <li>Responsible for all activities related to Manufacturing Engineering of Electronic Control Units (ECUs).</li>
                                    <li>Engineering change management implementation for existing products.</li>
                                    <li>Coordination of trial runs to meet project deliverables (i.e. Initial samples, EWAK-series, PV-runs).</li>
                                </ul>
                            </p>
                        </td>
                    </tr>

                </tbody></table>
                </div>
                <hr class="soft">
            
<!-- Publications -->
            <!--
                <button style="border:0px transparent; background-color: transparent;outline:none;"type="button" class="collapsible" data-toggle="collapse" data-target="#content-publications" id="publications"><heading>Publications</heading></button>
                <div id="content-publications" class="collapse in">

                <table border=0 class="bg_colour" style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/ad_text_model.png' width="150">
                            </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:top">
                            <papertitle><big>Multi-Modal Detection of Alzheimer's Disease from Speech and Text</papertitle></big>
                            <br>
                            <p>
                                <strong>Amish Mittal*</strong>, Sourav Sahoo*, Arnhav Datar*, Juned Kadiwala*, Hrithwik Shalu, Jimson Mathew
                                <br>
                            20th International Workshop on Data Mining in Bioinformatics (<strong>BIOKDD</strong>) with SIGKDD 2021
                            <br>
                            <em><a href="https://arxiv.org/abs/2012.00096" target="_blank">[paper]</a></em></p>
                            <p>
                                Reliable detection of the prodromal stages of Alzheimer's disease (AD) remains difficult even today because there is no definitive diagnosis of AD in vivo.
                                We propose a multimodal deep learning method that utilizes speech and the corresponding transcript simultaneously to detect AD.
                                We also perform experiments to analyze the model performance when ASR system generated transcripts are used and further perform an essential study of age and gender bias of our model. The proposed method achieves 85.3% 10-fold cross-validation accuracy on the Dementiabank Pitt corpus.
                            </p>
                            <p><small>*Authors contributed equally</small></p>
                        </td>
                    </tr>

                </tbody></table>
                </div>
                <hr class="soft">
            -->

<!-- Research Projects -->
            
                <button style="border:0px transparent; background-color: transparent;outline:none;"type="button" class="collapsible" data-toggle="collapse" data-target="#content-projects" id="projects"><heading>Research Projects</heading></button>
                <div id="content-projects" class="collapse in">

                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/tracking1.png' width="200">
                            </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:top">
                            <papertitle><big>FPGA implementation of adaptive subsampling.</papertitle></big>
                            <br>
                            <!-- <p><em><a href="https://github.com/fliptrail/quantum-state-NMR" target="_blank">[code]</a></em></p> -->
                            <p>
                                Implementation of an efficient adaptive subsampling pipeline involving a neural-network-based object detector (YoloV3, tinyYoloV3, ECO) and classical computer vision algorithms on a Xilinx FPGA board. 
                            </p>
                        </td>
                    </tr>
                       
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/eventDetector.png' width="200">
                            </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:top">
                            <papertitle><big>Event camera object tracker</papertitle></big>
                            <br>
                            <!--<p><em><a href="https://github.com/fliptrail/assembler-emulator" target="_blank">[code]</a></em></p> -->
                            <p>
                                Trained off-the-shelf neural networks to detect objects from a neuromorphic (event) camera dataset.
                                Leveraged use of representation techniques found in literature such as voxel-grid and intensity reconstruction from events.
                            </p>
                        </td>
                    </tr>
                    <!--
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/ue_multiplayer_game.png' width="150">
                            </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:top">
                            <papertitle><big>Prototype Multiplayer Parkour Video Game</papertitle></big>
                            <br>
                            <p><em><a href="https://www.youtube.com/watch?v=Z_01phvH1IM" target="_blank">[YouTube]</a></em></p>
                            <p>
                                Created the prototype of a functional multiplayer parkour video game using Unreal Engine 4; along with tutorial videos for it. Used State Machines to control behaviour and animations. It was my attempt to learn about behaviour states and OOPs. Programming Language used - C++.
                            </p>
                        </td>
                    </tr>

                    <!-- <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/dem_unc_boost.png' width="120">
                            </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:top">
                            <papertitle><big>Uncertainty-Aware Ensembling for Severity Prediction of Alzheimer‚Äôs Dementia</papertitle></big>
                            <br>
                            <p>
                            <em>Accepted for Oral Presentation at <a href="https://www.ijcnn.org/" target="_blank">IJCNN 2021</a>.
                            </em>
                            <br>
                            <em>Accepted at the <a href="https://ml4health.github.io/" target="_blank">Machine Learning for Health Workshop</a>, <a href="https://nips.cc/" target="_blank">NeurIPS 2020</a>.</em> 
                            </em><a href="https://arxiv.org/abs/2010.01440" target="_blank"> [preprint] </a><a href="https://github.com/wazeerzulfikar/alzheimers-dementia" target="_blank"> [code] </a></p>
                            <p>In this work, we propose an uncertainty-aware boosting technique for multi-modal ensembling to predict Alzheimer‚Äôs Dementia Severity. The propagation of uncertainty across acoustic, cognitive, and linguistic features produces an ensemble system robust  to heteroscedasticity in the data. Weighing the different modalities based on the uncertainty estimates, we experiment on the  benchmark ADReSS dataset to show that our method outperforms the state-of-the-art methods while also reducing the overall entropy of the system.</p>
                        </td>
                    </tr>

                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/dse_unc.png' width="120">
                            </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:top">
                            <papertitle><big>Disentangling Predictive Uncertainties using Deep Split Ensembles</papertitle></big>
                            <br>
                            <p><em>Under review </em><a href="https://arxiv.org/pdf/2009.12406.pdf" target="_blank">[preprint]</a> <a href="https://github.com/rishabkhincha/deep-split-ensembles" target="_blank">[code]</a> </p>
                            <p>We propose a conceptually simple non-Bayesian approach, deep split ensemble, to disentangle the predictive uncertainties using a multivariate Gaussian mixture model. The NNs are trained with clusters of input features, for uncertainty estimates per cluster. Extensive analyses using dataset shits and empirical rule highlight our inherently well-calibrated models. Our work further demonstrates its applicability in a multi-modal setting using a benchmark Alzheimer‚Äôs dataset and also shows how deep split ensembles can highlight hidden modality-specific biases</p>
                        </td>
                    </tr>

                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/missing_dendogram.png' width="120">
                            </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:top">
                            <papertitle><big>Robustness to Missing Features using Hierarchical Clustering with Split Neural Networks</papertitle></big>
                            <br>
                            <p><em>Accepted in the <a href="https://aaai.org/Conferences/AAAI-21/student-abstract-call/" target="_blank">Student Abstract Program</a>, <a href="https://aaai.org/Conferences/AAAI-21/" target="_blank">AAAI 2021</a></em><a href="https://github.com/rishabkhincha/Robustness-to-Missing-Features" target="_blank"> [code]</a></p>
                            <p>In this work, we propose a simple yet effective approach that clusters similar input features together using hierarchical clustering and then trains proportionately split neural networks with a joint loss. We evaluate this approach on a series of benchmark datasets and show promising improvements even with simple imputation techniques.</p>
                        </td>
                    </tr>

                    <tr onmouseout="covid_stop()" onmouseover="covid_start()" >
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                <div class="two" id='covid_gradcam'>
                                    <img src='images/covid_post.png' width="120">
                                </div>
                                <img src='images/covid_pre.png' width="120">
                            </div>
                            <script type="text/javascript">
                                function covid_start() {
                                    document.getElementById('covid_gradcam').style.opacity = "1";
                                }

                                function covid_stop() {
                                    document.getElementById('covid_gradcam').style.opacity = "0";
                                }
                                covid_stop()
                            </script>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:top">
                            <papertitle><big>CovidDiagnosis: Deep Diagnosis of COVID-19 Patients using Chest X-rays</papertitle></big>
                            <br>
                            <p><em>Accepted for oral presentation at the <a href="http://www.lungworkshop.org/" target="_blank">TIA Workshop</a>, <a href="https://miccai2020.org/" target="_blank">MICCAI 2020</a>.</em></p>
                            <p>Built a pipeline comprising of models for lung isolation, followed by classification into different disease classes. We further augment our network with symptom embeddings produced by the CheXpert network and achieve excellent results. Our visualisation maps provide trustworthy and interpretable decisions to radiologists for clinical deployment.</p>
                        </td>
                    </tr>

                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/lesion.jpg' width="120">
                            </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:top">
                            <papertitle><big>Knowledge Transfer in Lesions</big></papertitle>
                            <br>
                            <p><em>Accepted as a full paper at the <a href="https://www.hvnguyen.com/lesslabelsimperfectdataml2020" target="_blank">MIL3ID Workshop</a>, <a href="https://miccai2020.org/" target="_blank">MICCAI 2020</a>.</em> <a href="https://95217d1b-f241-44bb-939f-69f6fb5c41d2.usrfiles.com/ugd/95217d_c974b9219af6431999ad269a1ae28bb3.pdf" target="_blank"> [preprint] </a> <a href="data/A Case Study of Transfer of Lesion Knowledge-PPT.pdf" target="_blank"> [slides] </a></p>
                            <p>Studied the transfer of lesion knowledge across organs for lesion classifcation tasks. Our designed experiments on the lung and brain tumour datasets show that transfer learning using lesion-augmented models perform substantially better than models trained using random weights or lesion-agnostic(like ImageNet) transfer.</p>
                        </td>
                    </tr> 

                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/imagecube_pre.png' width="120">
                            </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:top">
                            <papertitle><big>ImageCube</big></papertitle>
                            <br>
                            <p><em><a href="data/PyAstro_invite.pdf" target="_blank">Invited</a> for an hour long talk at <a href="http://openastronomy.org/pyastro/2020/" target="_blank">PyAstro 2020</a>, Trinity College Dublin. </em><a href="https://github.com/rishabkhincha/ImageCube-1" target="_blank">[code]</a></p>
                            <p>Built an open source image processing tool in Python to process multi-wavelength astronomy images. On registereing the images from different telescope to a common world coordinate system, they are convolved and re-sampled to a common pixel scale. These images are now put together to form an image cube, to help for easy analysis.</p>
                        </td>
                    </tr> 

                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/apnea_post.png' width="120">
                            </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:top">
                            <papertitle><big>Sleep Apnea Detection on an Embedded Device</big></papertitle>
                            <br>
                            <p><em>Accepted as a <a href="https://link.springer.com/chapter/10.1007/978-3-030-51935-3_40" target="_blank">full paper</a> at <a href="http://icisp-conf.org/" target="_blank">ICISP 2020</a>.</em> <a href="https://github.com/rishabkhincha/SleepApneaDetector" target="_blank">[code]</a></p>
                            <p>We developed a data analysis pipeline combining dataset extraction, segmentation, signal cleaning and filtration to detect the presence of sleep apnea using SVMs. On testing our approach on the MIT-Physionet dataset, we find that the low computational complexity makes it well suited for deployment on embedded devices such as the Raspberry Pi.</p>
                        </td>
                    </tr> 

                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/socialnetwork_post.png' width="120">
                            </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:top">
                            <papertitle><big>Online Learning Assistant with Network Community Analysis</big></papertitle>
                            <br>
                            <p><em>Accepted at the Young Researcher's Symposium, <a href="https://cods-comad.in/" target="_blank">CODS-COMAD 2021</a></em></p>
                            <p>Built a simple and scalable platform agnostic tool to aid online discussion forums using Social Network Analysis. We extract keywords from a chat, and list out the top users for this keyword and their activity histograms using a sliding window exponential ranking system. We have tested our methodology on Ubuntu IRC Logs and on our university chat for courses.</p>
                        </td>
                    </tr>  
                    
            -->        
                </tbody></table>
                </div>
                <hr class="soft">
                  

<!-- Academic Projects -->
            
                <button style="border:0px transparent; background-color: transparent;outline:none;"type="button" class="collapsible" data-toggle="collapse" data-target="#content-projects" id="projects"><heading>Academic Projects</heading></button>
                <div id="content-projects" class="collapse in">

                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/nmnist.png' width="150">
                            </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:top">
                            <papertitle><big>N-MNIST object tracker.</papertitle></big>
                            <br>
                            <!-- <p><em><a href="https://github.com/fliptrail/quantum-state-NMR" target="_blank">[code]</a></em></p> -->
                            <p>
                                Trained custom Convolutional Neural Network to perform detection and classification of MNIST digits captured with an event camera. 
                            </p>
                        </td>
                    </tr>

                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/denoising.png' width="200">
                            </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:top">
                            <papertitle><big>Denoising neural network.</papertitle></big>
                            <br>
                            <!-- <p><em><a href="https://github.com/fliptrail/quantum-state-NMR" target="_blank">[code]</a></em></p> -->
                            <p>
                                Trained UNet to correct noisy images.  Custom dataset generated by simulating photon-shot noise, read noise and ADC noise.
                            </p>
                        </td>
                    </tr>

                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                <img src='images/layout.png' width="200">
                            </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:top">
                            <papertitle><big>Conv-Pool engine design.</papertitle></big>
                            <br>
                            <!-- <p><em><a href="https://github.com/fliptrail/quantum-state-NMR" target="_blank">[code]</a></em></p> -->
                            <p>
                                Developed a 4x4 convolution and maxpooling engine for deep learning applications and implemented on 7nm CMOS technology.
                                Wrote behavioral System Verilog module.  Synthesized using Design Compiler.  Performed palce-and-route using Innovus.
                                Accomplished DRC and LVS clean in Virtuoso.  Assured functional verification at every step.
                            </p>
                        </td>
                    </tr>

                </tbody></table>
                </div>
                <hr class="soft">
                  
            </td>
        </tr>

    </table>

</body>

</html>
